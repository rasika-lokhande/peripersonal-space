\chapter{General Discussion} 
\label{discussion} 
\lhead{Chapter 5. \emph{General Discussion}} 

The purpose of this thesis was to investigate the following questions: i) Is the spatial information of the target of reach action represented with respect to body-part situated in its proximity, even if that body-part is not the effector involved in the reach action? ii) If yes, and considering that visuo-proprioceptive integration mechanism may underlie the construction of the representation of the body (\textit{body schema}), how is the integration of visual and proprioceptive signals specifying the spatial parameters of the proximal body-part involved in the spatial encoding of the reach target? To investigate these questions, we experimentally manipulated the presence of visual and proprioceptive information of a body-part proximal to the reach action target, and measured the accuracy of the target location estimated by the subjects in reaching action. 

The results of Experiment 1 show that when a body part is present proximal to the target, the target location estimation is more accurate, compared to the situation in which the body-part is not present proximal to the target. This result thus supports the hypothesis that spatial information of the target is indeed represented in an egocentric reference frame, with respect to the body-part proximal to the target. Thus, our finding confirms the results from previous literature that the objects in peri-personal space (here, the reach targets) are spatially encoded in a somatotopic (body-part centric) frame of reference \cite{serino2019peripersonal}. Notably, we have shown that this hypothesis is further supported through the paradigm of accuracy of reaches, and not merely through the paradigm of multi-sensory interaction effects, that has been a norm in the literature (See Chapter \ref{Literature Review}).

However, the target location estimation is not improved significantly when only uni-sensory information (visual or proprioceptive) about the proximal body-part is present. This is a significant finding, because it suggests that it is more merely the presence of a visual allocentric landmark that is affecting the target location estimation. Rather, the accuracy in target location estimation is improved only when multi-sensory visuo-proprioceptive signals of proximal body part are present. This suggests that visuo-proprioceptive multi-sensory integration mechanism plays a role in the spatial encoding of the reach target. This contradicts the results from various studies that show that presence of visual landmarks improves reaching performance \cite<e.g.>{krigolson2007proximity}; \cite<For review, see>{filimon2015all}. However, these studies used memory guided reach paradigm, instead of invisible action-hand reach paradigm to induce variability in the reaches. It is possible that memory-guided reaches have another (allocentric) mechanism underlying the reach target spatial encoding. 

\citeA{fossataro2020immersive} showed that when there is high visuo-proprioceptive discrepancy of a body-part, the peri-personal space as operationalized by the magnitude of multi-sensory interactions, enlarges, suggesting that since the estimation of body-part position (according to Bayesian Casual Inference) is less precise due to the high visuo-proprioceptive discrepancy, peri-personal space is enlarged to optimize reactions to external events. Particularly, their findings show that the magnitude of multi-sensory interaction effects are comparable when the visual stimuli occurs near to the proprioceptive or the visual signal of the body part. Our results contradict \citeA{fossataro2020immersive}'s finding that the inference of body-part position affecting the spatial encoding of visual objects in peri-personal space. When visuo-proprioceptive spatial discrepancy is induced in the proximal body-part, the results of the experiment show that the estimation of the target is "pulled" towards the proximal body-part as a function of proximity of the target to the visual signal. This finding suggests that although the results from the previous experiment suggest that a body-part proximal multi-sensory integration mechanism underlies the spatial encoding of the target, the spatial encoding itself seems to occur with respect to the visual signal regarding the proximal body-part. Furthermore, we implemented the Bayesian Causal Inference Model to estimate the inferred location of the proximal body-part based on inputs from the spatially discrepant visual and proprioceptive signals. These inferred proximal body-part positions do not systematically explain the reach errors measured in the experiment. Thus, our results do not support the hypothesis that the reach target is spatially encoded with respect to the position of the proximal body-part as inferred from a multi-sensory integration process by an ideal Bayesian observer. 

The discrepancies between the results may be due to the difference in the paradigms implemented in the two studies. In our experiment, we implemented a localization of visual stimuli in peri-personal space paradigm, while \citeA{fossataro2020immersive} implemented a multi-sensory interaction effects paradigm which is based on reaction times. It is plausible that the spatial properties attributed to the multi-sensory interaction effects observed in peri-personal space and the the spatial encoding of objects in peri-personal space may have different conceptual and mechanistic basis. Indeed, \citeA{bufacchi2021peripersonal} have discussed the idea that there is not a single peri-personal space representation, rather, a set of responses arising in the space surrounding the body, which may be indicative of distinct cognitive processes. 

Overall, our novel findings are i) Multi-sensory visuo-proprioceptive information of the proximal body part may be necessary for the spatial encoding of reach target to occur with respect to it, however ii) the encoding may occur with respect to the visual signal, as opposed to the inferred position of the proximal body-part estimated by an Ideal Bayesian observer. There are however several limitations of our study which must be acknowledged. Firstly, there are some intrinsic limitations in our experimental design. The distance between proprioceptive signal and the target (which keeping the distance between the action hand and target constant) has been been systematically manipulated, which prevents us from making stronger claims regarding the spatial encoding of the target with respect to the proprioceptive signal. Secondly, in our study, the Bayesian Causal inference Model has been implemented to get predictions regarding the inferred body-part position according to an ideal Bayesian observer, and reach responses are compared for different levels of proximity of inferred body-part position to the reach target. While our results and analysis merely point towards the probable multi-sensory mechanism, a stronger case can be made if the reach error itself can be modeled in the Bayesian Causal Inference framework, while experimentally determining the parameters for the model. 

In summary, the findings from our work suggest that a proximal body-part's visuo-proprioceptive multi-sensory integration mechanism underlies the spatial encoding of reach target, and that the spatial encoding occurs with respect to the visual information before integration with the proprioceptive information, however, further empirical investigation is required to substantiate this  claim.







